{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree sequence characterisation of the UK Biobank using tsinfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By [Chaimaa Fadil](https://github.com/chaimaafadil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publication - ***Inferring whole-genome histories in large population datasets***\n",
    "\n",
    "*External data licensing:*\n",
    "*The boundary data referenced in this notebook are provided by the Office for National Statistics (ONS), the Ordnance Survey and the Database of Global Administrative Areas (GADM). It contains public sector information licensed under the [Open Government Licence v3.0](http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code for plotting Figure 5 of the publication 'Inferring whole-genome histories in large population datasets'. The aim of this analysis was to assess the performance of [tsinfer](https://tsinfer.readthedocs.io/en/latest/) on vast data sets such as the UK Biobank which comprises the SNP array data of ~500K individuals.\n",
    "\n",
    "With [tsinfer](https://tsinfer.readthedocs.io/en/latest/), we constructed a tree sequence for the UK Biobank (UKB) on human chromosme 20. Note that this notebook does not include the code for constructing the tree sequence. We used the tree sequence to characterise ancestral relationships between UKB individuals by computing the GNN proportions of each individual (see paper for discussion on GNNs). We then generated plots to (1) visualise the population structure resulting from the GNN structure of the tree sequence and (2) characterise the relationship between geographical proximity of birth locations and genetic relatedness. Please refer to the publication above for further discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is structured into 3 sections:\n",
    "\n",
    "* In **Section 1** we determine the birth location of all individuals in the UKB with reported birth coordinates. The UKB provides birth coordinates for individuals born in Great Britain (England, Wales and Scotland). These coordinates are encoded in the British National Grid (BNG) reference system. We reverse-geocode these coordinates to determine the name of the region in which a person was born. We define regions in the UK as per the [NUTS](https://en.wikipedia.org/wiki/NUTS_statistical_regions_of_the_United_Kingdom) territorial subdivision system. The NUTS subdivision of the UK is defined at 3 levels. We chose to map individuals' birth coordinates to both NUTS Level-2 and NUTS Level-3 areas.\n",
    "\n",
    "\n",
    "* In **Section 2** we generate 2 matrices of GNN proportions by computing the GNNs of each individual in the UKB using as reference sets individuals' NUTS-2 and NUTS-3 birth locations, respectively. The GNNs are computed from the tree sequence constructed previously. Note that a path to the tree sequence `ts_path` is required as input.\n",
    "\n",
    "\n",
    "* In **Section 3** we use the data generated in sections 1 and 2 to plot the different panels of Figure 5, that is, visual representations (1) of the GNN matrix and (2) of the geographical clustering of relatedness between. Note that panels A and B of Figure 5 rely on the NUTS-2 subdivision of the UK, while panels C, D and E, on the NUTS-3 subdivision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional notes on the execution of this notebook:**\n",
    "* The 3 main sections of this notebook need to be run in numerical order as each section following section 1.1 is dependent on variables created in previous sections.\n",
    "* The input files for each section are listed only for reference. It is not necessary to load them if the script is being run in one sitting.\n",
    "* For the boundary vector shapefiles, the link to download these files is provided in the markdown. These come in the form of zipped folders. Make sure to unzip the folder and place it in the same directory as this notebook. The folder should have the same name as the one indicated in the code.\n",
    "* The input files used in section 1.2 for the names and countries of NUTS areas are provided with this notebook. The code to load them is already included in the script and assumes that they are located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Various libraries used throughout the notebook\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tskit\n",
    "\n",
    "import scipy\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPoint\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reverse-geocode places of birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Map BNG (Easting, Northing) coordinates to NUTS Level 2 and Level 3 areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Input files:** \n",
    "* `ukb_metadata.csv` - Raw dataframe with individuals' IDs and birth coordinates defined under the Ordnance Survey National Grid reference system (also referred to as British National Grid - BNG). In this code, `ukb_metadata.csv` contains in each row data relating to a single individual. This data is organised into the following 5 columns:\n",
    "    * `SampleID`\n",
    "    * `Ethnicity`\n",
    "    * `PlaceOfBirthUK_East` (person's easting birth coordinate)\n",
    "    * `PlaceOfBirthUK_North` (person's northing birth coordinate)\n",
    "    * `CountryOfBirth_UK` (person's country of birth if born in the UK. If not, the field is specified as 'NaN') \n",
    "    \n",
    "* Boundary vectors for:\n",
    "    * [NUTS Level 2 areas](https://data.gov.uk/dataset/e65fbc2a-7314-450f-b4a1-14ba87378b3c/nuts-level-2-january-2018-generalised-clipped-boundaries-in-the-united-kingdom): `NUTS_Level_2_January_2018_Generalised_Clipped_Boundaries_in_the_United_Kingdom`;\n",
    "    * [NUTS Level 3 areas](https://data.gov.uk/dataset/0c9bc79f-e3d2-4955-aa5c-cd43bae9c67a/nuts-level-3-january-2018-generalised-clipped-boundaries-in-the-united-kingdom): `NUTS_Level_3_January_2018_Generalised_Clipped_Boundaries_in_the_United_Kingdom`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the raw dataframe containing individuals' places of birth encoded in BNG coordinates (eastings and northings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframes and add a column to store NUTS birth locations.\n",
    "def get_input_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['PlaceOfBirth_NUTS'] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_nuts2_df = get_input_df(\"ukb_metadata.csv\")\n",
    "ukb_nuts3_df = get_input_df(\"ukb_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import the vector boundary data for the 41 NUTS-2 areas and the 179 NUTS-3 areas. This data contains the polygons and names of each NUTS area. The polygons are defined by digital vector boundaries for NUTS-2 and NUTS-3 areas in the UK as of January 2018. The boundaries are available at different resolutions - we use here the generalised clipped boundaries. \n",
    "\n",
    "This data was published by the Office for National Statistics and can be downloaded as a **shapefile** from the UK government open database for [NUTS-2](https://data.gov.uk/dataset/e65fbc2a-7314-450f-b4a1-14ba87378b3c/nuts-level-2-january-2018-generalised-clipped-boundaries-in-the-united-kingdom) and [NUTS-3](https://data.gov.uk/dataset/0c9bc79f-e3d2-4955-aa5c-cd43bae9c67a/nuts-level-3-january-2018-generalised-clipped-boundaries-in-the-united-kingdom) areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NUTS polygons and names and create a dataframe of polygons, poly_df.\n",
    "def get_nuts_polygons(nuts_path, name_field, code_field):\n",
    "    # Get NUTS polygons and names\n",
    "    area_path = nuts_path\n",
    "    reader = shpreader.Reader(area_path)\n",
    "    geometries = list(reader.geometries())\n",
    "    names = [record.attributes[name_field] for record in reader.records()]\n",
    "    codes = [record.attributes[code_field] for record in reader.records()]\n",
    "    # Create dataframe of polygons\n",
    "    poly_df = pd.DataFrame({\n",
    "        'geometry': geometries,\n",
    "        'name': names,\n",
    "        'code': codes\n",
    "    })\n",
    "    return poly_df\n",
    "\n",
    "# Update the NUTS-3 poly_df to account for individuals born in Northern Ireland (see 'note on individuals born in Northern Ireland' below).\n",
    "# This function adds the NUTS-2 polygon for Northern Ireland to poly_df_nuts3 and deletes NUTS-3 polygons located in Northern Ireland.\n",
    "def update_nuts3_polygons(poly_df_nuts3, poly_df_nuts2):\n",
    "    # Remove NUTS-3 polygons located in Northern Ireland\n",
    "    NIR = ['Antrim and Newtownabbey','Ards and North Down','Armagh City, Banbridge and Craigavon','Belfast',\n",
    "           'Causeway Coast and Glens','Derry City and Strabane','Fermanagh and Omagh','Lisburn and Castlereagh',\n",
    "           'Mid Ulster','Mid and East Antrim','Newry, Mourne and Down']\n",
    "    NIR_index = poly_df_nuts3.loc[poly_df_nuts3.name.isin(NIR),:].index.values\n",
    "    poly_df_nuts3 = poly_df_nuts3.drop(NIR_index)\n",
    "    # Add \"Northern Ireland\" to poly_df_nuts3\n",
    "    NIR = poly_df_nuts2.loc[poly_df_nuts2['name']=='Northern Ireland',:]\n",
    "    poly_df_nuts3 = poly_df_nuts3.append(NIR, ignore_index=True)\n",
    "    return poly_df_nuts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df_nuts2 = get_nuts_polygons(\"NUTS_Level_2_January_2018_Generalised_Clipped_Boundaries_in_the_United_Kingdom/NUTS_Level_2_January_2018_Generalised_Clipped_Boundaries_in_the_United_Kingdom\", \"nuts218nm\", \"nuts218cd\")\n",
    "poly_df_nuts3 = get_nuts_polygons(\"NUTS_Level_3_January_2018_Generalised_Clipped_Boundaries_in_the_United_Kingdom/NUTS_Level_3_January_2018_Generalised_Clipped_Boundaries_in_the_United_Kingdom\", \"nuts318nm\", \"nuts318cd\")\n",
    "poly_df_nuts3 = update_nuts3_polygons(poly_df_nuts3, poly_df_nuts2) # See note below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on individuals born in Northern Ireland:**\n",
    "\n",
    "In the UKB, individuals born in Northern Ireland have no reported birth coordinates. Their place of birth is only reported through the `CountryOfBirth_UK` field as \"Northern Ireland\". We are therefore unable to reverse-geocode their birth location. As we still want to include them in our analysis, we will manually report their NUTS-2 and NUTS-3 birth location as \"Northern Ireland\".\n",
    "\n",
    "Since \"Northern Ireland\" is a NUTS-2 and not a NUTS-3 area, we modified `poly_df_nuts3` above with `update_nuts3_polygons` to include a polygon for the area of \"Northern Ireland\". We also removed the 11 NUTS-3 areas located in Northern Ireland which we won't use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we reverse-geocode birth locations. We use as input individuals' birth coordinates and map those to a NUTS area. We do so using as reference both NUTS-2 and NUTS-3 subdivisions.\n",
    "\n",
    "The function `reverse-geocode` takes as input the UKB dataframe `ukb_df` which contains individuals' BNG birth coordinates and the dataframe of polygons `poly_df` created in the previous step. For each birth coordinate tuple (easting and northing), the function outputs the name of the NUTS (2 or 3) area in which the point encoded by the coordinates is located in. The function operates in 3 steps:\n",
    "\n",
    "1. `checkCoordinates` verifies that the coordinates are not `NaN`. Note that in the UKB, place of birth coordinates are only given for individuals born in Great Britain.\n",
    "2. `OSGB36toWGS84` converts the BNG coordinates (OSGB36) to latitude/longitude coordinates (WGS84).\n",
    "3. `LatLonToAddress` uses the `within()` function to map the latitude/longitude coordinates to one of the polygons in `poly_df` and outputs the name of the polygon.\n",
    "\n",
    "Note: if your coordinates are given in latitudes and longitudes, you can modify `reverse-geocode` to skip step (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bng_to_latlon import OSGB36toWGS84\n",
    "# Library: https://pypi.org/project/bng-latlon/\n",
    "\n",
    "def checkCoordinates(easting,northing):\n",
    "    return (not(np.isnan(easting) and np.isnan(northing)))\n",
    "\n",
    "def LatLonToAddress(latlon, poly_df):\n",
    "    p = Point(latlon[1],latlon[0])\n",
    "    # Find polygon\n",
    "    for index in poly_df.index:\n",
    "        if p.within(poly_df.at[index,'geometry']):\n",
    "            return poly_df.at[index,'name']\n",
    "            break\n",
    "    return np.nan\n",
    "\n",
    "def reverse_geocode(ukb_df, poly_df):\n",
    "    for index in ukb_df.index:\n",
    "        easting = ukb_df.at[index,'PlaceOfBirthUK_East']\n",
    "        northing = ukb_df.at[index,'PlaceOfBirthUK_North']\n",
    "        if checkCoordinates(easting, northing):\n",
    "            try:\n",
    "                latlon = OSGB36toWGS84(easting, northing)\n",
    "                address = LatLonToAddress(latlon, poly_df)\n",
    "                ukb_df.loc[index, 'PlaceOfBirth_NUTS'] = address\n",
    "            except:\n",
    "                print(\"Exception at \", index)\n",
    "    # Manually map all individuals born in Northern Ireland to \"Northern Ireland\" (see note above)\n",
    "    ukb_df.loc[ukb_df['CountryOfBirth_UK']=='Northern Ireland', 'PlaceOfBirth_NUTS'] = 'Northern Ireland'\n",
    "    return ukb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this step will take a few hours to run. A more efficient approach would be to run it on different parts \n",
    "# of the dataframe in parallel then merge the outputs.\n",
    "ukb_nuts2_df = reverse_geocode(ukb_nuts2_df, poly_df_nuts2)\n",
    "ukb_nuts3_df = reverse_geocode(ukb_nuts3_df, poly_df_nuts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "ukb_nuts2_df.to_csv(\"ukb_reverse_geocoded_nuts2.csv\", index=False)\n",
    "ukb_nuts3_df.to_csv(\"ukb_reverse_geocoded_nuts3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Output files:**\n",
    "* `ukb_reverse_geocoded_nuts2.csv` - UKB dataframe with birth locations reverse-geocoded to NUTS-2 areas.\n",
    "* `ukb_reverse_geocoded_nuts3.csv` - UKB dataframe with birth locations reverse-geocoded to NUTS-3 areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clean the dataset by removing any inconsistencies in the reverse-geocoding of birth locations\n",
    "\n",
    "Among the individuals with reported birth coordinates that were reverse-geocoded in the previous step, we suggest to delete individuals who:\n",
    "1. **Were not mapped to any NUTS area.** That is usually the case for individuals with birth coordinates mapping to bodies of water that are outside NUTS polygons. For example, one individual's birth coordinates mapped to a point in the Atlantic Ocean.\n",
    "    \n",
    "2. **Were mapped to a NUTS area that is not located within their reported country of birth.** For example, an individual's birth coordinates mapped to an area in East Wales while their country of birth was reported as 'England' in the `CountryOfBirth_UK` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Input files:**\n",
    "* `ukb_reverse_geocoded_nuts2.csv` - UKB dataframe with birth locations reverse-geocoded to NUTS-2 areas.\n",
    "* `ukb_reverse_geocoded_nuts2.csv` - UKB dataframe with birth locations reverse-geocoded to NUTS-3 areas.\n",
    "* `UK_NUTS_Level_2_January_2018_Names_and_Countries.csv` - Name and country of NUTS-2 areas.\n",
    "* `UK_NUTS_Level_3_January_2018_Names_and_Countries.csv` - Name and country of NUTS-3 areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select individuals born in Great Britain with reported birth coordinates.\n",
    "def get_gb_inds(ukb_df):\n",
    "    countries = ['England','Scotland','Wales']\n",
    "    GB_inds = ukb_df[ukb_df['CountryOfBirth_UK'].isin(countries)]\n",
    "    GB_inds = GB_inds[GB_inds['PlaceOfBirthUK_East'].notnull()]\n",
    "    return GB_inds\n",
    "\n",
    "# Read dataframes of nuts countries.\n",
    "def get_nuts_countries(countries_path):\n",
    "    nuts_countries = pd.read_csv(countries_path, index_col='name')\n",
    "    return nuts_countries\n",
    "\n",
    "# Get list of individuals with 'NaN' or inconsistent birth locations.\n",
    "def get_inds_to_delete(GB_inds, countries_path):\n",
    "    deleted_inds = list()\n",
    "    # Select individuals that were not mapped to a NUTS area\n",
    "    deleted_inds.extend(list(GB_inds[GB_inds['PlaceOfBirth_NUTS'].isnull()].index.values))\n",
    "    GB_inds = GB_inds.drop(deleted_inds)\n",
    "    # Select individuals that were mapped to a NUTS area that is not located in their reported country of birth\n",
    "    nuts_countries = get_nuts_countries(countries_path)\n",
    "    for index in GB_inds.index:\n",
    "        nuts = GB_inds.at[index, 'PlaceOfBirth_NUTS']\n",
    "        nuts_country = nuts_countries.at[nuts,'country']\n",
    "        country_of_birth = GB_inds.at[index, 'CountryOfBirth_UK']\n",
    "        if nuts_country!=country_of_birth:\n",
    "            deleted_inds.append(index)\n",
    "    return deleted_inds\n",
    " \n",
    "# Delete individuals with no or inconsistent reverse-geocoding of birth locations from dataframe.\n",
    "def clean_reverse_geocoding(ukb_df, countries_path):\n",
    "    GB_inds = get_gb_inds(ukb_df)\n",
    "    deleted_inds = get_inds_to_delete(GB_inds, countries_path)\n",
    "    ukb_df = ukb_df.drop(deleted_inds)\n",
    "    return ukb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cleaned dataframes\n",
    "ukb_nuts2_df = clean_reverse_geocoding(ukb_nuts2_df, \"UK_NUTS_Level_2_January_2018_Names_and_Countries.csv\")\n",
    "ukb_nuts3_df = clean_reverse_geocoding(ukb_nuts3_df, \"UK_NUTS_Level_3_January_2018_Names_and_Countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "ukb_nuts2_df.to_csv(\"ukb_reverse_geocoded_cleaned_nuts2.csv\", index=False)\n",
    "ukb_nuts3_df.to_csv(\"ukb_reverse_geocoded_cleaned_nuts3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Output files**\n",
    "* `ukb_reverse_geocoded_cleaned_nuts2.csv` - UKB dataframe after reverse-geocoding to NUTS-2 and cleaning.\n",
    "* `ukb_reverse_geocoded_cleaned_nuts3.csv` - UKB dataframe after reverse-geocoding to NUTS-3 and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute GNN matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Input files:**\n",
    "* `ukb_reverse_geocoded_cleaned_nuts2.csv` - UKB dataframe after reverse-geocoding to NUTS-2 and cleaning.\n",
    "* `ukb_reverse_geocoded_cleaned_nuts3.csv` - UKB dataframe after reverse-geocoding to NUTS-3 and cleaning.\n",
    "* `ts_path` - Path to the tree sequence constructed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute the GNN matrix\n",
    "\n",
    "\"\"\"\n",
    "Various utilities for manipulating tree sequences and running tsinfer.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import subprocess\n",
    "import time\n",
    "import collections\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "import csv\n",
    "import itertools\n",
    "import os.path\n",
    "\n",
    "import msprime\n",
    "import tsinfer\n",
    "import daiquiri\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import humanize\n",
    "import cyvcf2\n",
    "\n",
    "# Create dictionary of individuals' ethnicity and NUTS birth location\n",
    "def get_ukb_dict(ukb_df):\n",
    "    ukb_dict = {}\n",
    "    for index in ukb_df.index:\n",
    "        ukb_dict[ukb_df.at[index,'SampleID']] = {\n",
    "            'Ethnicity': ukb_df.at[index,'Ethnicity'],\n",
    "            'PlaceOfBirth_NUTS': ukb_df.at[index,'PlaceOfBirth_NUTS'],\n",
    "    }\n",
    "    return ukb_dict\n",
    "\n",
    "def get_augmented_samples(tables):\n",
    "    # Shortcut. Iterating over all the IDs is very slow here.\n",
    "    # Note that we don't necessarily recover all of the samples that were \n",
    "    # augmented here because they might have been simplified out.\n",
    "    # return np.load(\"ukbb_chr20.augmented_samples.npy\")\n",
    "    nodes = tables.nodes\n",
    "    ids = np.where(nodes.flags == tsinfer.NODE_IS_SAMPLE_ANCESTOR)[0]\n",
    "    sample_ids = np.zeros(len(ids), dtype=int)\n",
    "    for j, node_id in enumerate(tqdm.tqdm(ids)):\n",
    "        offset = nodes.metadata_offset[node_id: node_id + 2]       \n",
    "        buff = bytearray(nodes.metadata[offset[0]: offset[1]])\n",
    "        md = json.loads(buff.decode())       \n",
    "        sample_ids[j] = md[\"sample\"]\n",
    "    return sample_ids   \n",
    "\n",
    "def run_compute_ukbb_gnn_get_augmented(ts_path):\n",
    "    ts = tskit.load(ts_path)\n",
    "    tables = ts.tables\n",
    "    before = time.time()\n",
    "    augmented_samples = set(get_augmented_samples(tables))\n",
    "    duration = time.time() - before\n",
    "    print(\"Got augmented:\", len(augmented_samples), \"in \", duration)\n",
    "    return augmented_samples\n",
    " \n",
    "def run_compute_ukbb_gnn(ts_path, augmented_samples, ukb_dict):\n",
    "    ts = tskit.load(ts_path)\n",
    "    tables = ts.tables\n",
    "    before = time.time()\n",
    "\n",
    "    reference_sets_map = collections.defaultdict(list)\n",
    "    ind_metadata = [None for _ in range(ts.num_individuals)]\n",
    "    all_samples = []\n",
    "\n",
    "    for ind in ts.individuals():\n",
    "        md = json.loads(ind.metadata.decode())\n",
    "        \n",
    "        try:\n",
    "            sample = ukb_dict[int(md[\"SampleID\"])]\n",
    "            if type(sample[\"PlaceOfBirth_NUTS\"])!=float:\n",
    "                md[\"PlaceOfBirth\"] = ukb_dict[int(md[\"SampleID\"])][\"PlaceOfBirth_NUTS\"]\n",
    "            else:\n",
    "                md[\"PlaceOfBirth\"]=np.nan\n",
    "                \n",
    "        except KeyError:\n",
    "            # Individuals not in dictionary (e.g. removed in step 1.2)\n",
    "            md[\"PlaceOfBirth\"] = np.nan\n",
    "            pass\n",
    "\n",
    "        ind_metadata[ind.id] = md\n",
    "        for node in ind.nodes:\n",
    "            if node not in augmented_samples:\n",
    "                reference_sets_map[md[\"PlaceOfBirth\"]].append(node)\n",
    "                all_samples.append(node)\n",
    "\n",
    "    reference_set_names = list(reference_sets_map.keys())\n",
    "    reference_sets = [reference_sets_map[key] for key in reference_set_names]\n",
    "    \n",
    "    cols = {\n",
    "        \"place_of_birth\": [\n",
    "            ind_metadata[ts.node(u).individual][\"PlaceOfBirth\"] for u in all_samples],\n",
    "        \"sample_id\": [\n",
    "            ind_metadata[ts.node(u).individual][\"SampleID\"] for u in all_samples],\n",
    "        \"ethnicity\": [\n",
    "            ind_metadata[ts.node(u).individual][\"Ethnicity\"] for u in all_samples],\n",
    "    }\n",
    "\n",
    "    print(\"Computing GNNs for \", len(all_samples), \"samples\")\n",
    "    before = time.time()\n",
    "    A = ts.genealogical_nearest_neighbours(all_samples, reference_sets, num_threads=16)\n",
    "    duration = time.time() - before\n",
    "    print(\"Done in {:.2f} mins\".format(duration / 60))\n",
    "\n",
    "    for j, name in enumerate(reference_set_names):\n",
    "        cols[name] = A[:, j]\n",
    "    gnn_df = pd.DataFrame(cols)\n",
    "    return gnn_df\n",
    "\n",
    "# Main function to compute GNNs for the UKB using NUTS areas as reference sets\n",
    "def compute_gnn(ts_path, ukb_df, augmented_samples):\n",
    "    ukb_dict = get_ukb_dict(ukb_df)\n",
    "    gnn_df = run_compute_ukbb_gnn(ts_path, augmented_samples, ukb_dict)\n",
    "    return gnn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get augmented samples\n",
    "ts_path = \"\" # Add path to tree sequence\n",
    "augmented_samples = run_compute_ukbb_gnn_get_augmented(ts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute GNNs for NUTS-2 and NUTS-3 mappings\n",
    "print('Computing GNNs for NUTS-2')\n",
    "gnn_nuts2_df = compute_gnn(ts_path, ukb_nuts2_df, augmented_samples)\n",
    "print('Computing GNNs for NUTS-3')\n",
    "gnn_nuts3_df = compute_gnn(ts_path, ukb_nuts3_df, augmented_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "gnn_nuts2_df.to_csv(\"gnn_nuts2.csv\", index=False)\n",
    "gnn_nuts3_df.to_csv(\"gnn_nuts3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Output files:**\n",
    "* `gnn_nuts2.csv` - GNN matrix computed using NUTS-2 areas as reference sets.\n",
    "* `gnn_nuts3.csv` - GNN matrix computed using NUTS-3 areas as reference sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot a heatmap and geographical representation of the GNN matrix\n",
    "See Figure 5 on the tsinfer paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Input files:**\n",
    "* `gnn_nuts2.csv` - GNN matrix computed using NUTS-2 areas as reference sets.\n",
    "* `gnn_nuts3.csv` - GNN matrix computed using NUTS-3 areas as reference sets.\n",
    "* `poly_df_nuts2` - Dataframe of NUTS-2 polygons created in (1.1).\n",
    "* `poly_df_nuts3` - Dataframe of NUTS-3 polygons created in (1.1).\n",
    "* `gadm36_IRL_shp/gadm36_IRL_0` - Republic of Ireland boundary vectors. The shapefile can be downloaded from the Database of Global Administrative Areas [here](https://gadm.org/download_country_v3.html) by inputting \"Ireland\" as country and selecting the 'Shapefile' link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Reformat GNN dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average GNN proportions by NUTS area and z-score columns\n",
    "def group_normalise_gnns(gnn_df):\n",
    "    # Group rows by NUTS area and take the average of their GNN scores\n",
    "    gnn_dfg = gnn_df.iloc[:,3:].groupby(gnn_df.place_of_birth).mean()\n",
    "    # Z-score GNN proportions\n",
    "    for col in list(gnn_dfg):\n",
    "        gnn_dfg[col] = stats.zscore(gnn_dfg[col])\n",
    "    return gnn_dfg\n",
    "\n",
    "# Remove nan or empty columns and rows that do not correspond to a NUTS area.\n",
    "# These result from individuals who have not been mapped to any NUTS-area\n",
    "def clean_gnn(gnn_dfg, poly_df):\n",
    "    for col in gnn_dfg.columns:\n",
    "        if str(col) not in list(poly_df['name']):\n",
    "            gnn_dfg = gnn_dfg.drop(col, axis=1)\n",
    "    for index in gnn_dfg:\n",
    "        if str(index) not in list(poly_df['name']):\n",
    "            gnn_dfg = gnn_dfg.drop(index)\n",
    "    return gnn_dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_nuts2_dfg = clean_gnn(group_normalise_gnns(gnn_nuts2_df), poly_df_nuts2)\n",
    "gnn_nuts3_dfg = clean_gnn(group_normalise_gnns(gnn_nuts3_df), poly_df_nuts3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Import boundary data for Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_path_RI = \"gadm36_IRL_shp/gadm36_IRL_0\"\n",
    "reader_RI = shpreader.Reader(area_path_RI)\n",
    "geometries_RI = list(reader_RI.geometries())\n",
    "names_RI = [record.attributes[\"NAME_0\"] for record in reader_RI.records()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plot the NUTS-2 GNN matrix heatmap and UK geographical map color-coded by hierarchical clustering \n",
    "See Figure 5A, 5B on the tsinfer paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Cluster NUTS-2 areas by hierarchical clustering and divide the resulting tree into *n* subtrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this section is to cluster the reference areas in `gnn_dfg` by hierachical clustering and divide the resulting tree into n subtrees or clusters. In (3.2.3), we create a map of the UK where each area is colour-coded based on the subtree it falls in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that hierarchically clusters a dataframe and outputs a tree object.\n",
    "def get_tree(df, method='average'):\n",
    "    row_linkage = hierarchy.linkage(df, method=method)\n",
    "    tree = hierarchy.to_tree(row_linkage, rd=True)\n",
    "    return tree\n",
    "\n",
    "# Function that takes as input a scipy tree object and a desired number of subtrees and outputs the list of nodes \n",
    "# at the root of each subtree. The function traverses the tree nodes starting from the root node and stops once\n",
    "# it has traversed a number of nodes equal to the number of desired subtrees.\n",
    "def get_cluster_nodes(tree, n_subtrees):\n",
    "    all_nodes = tree[1][::-1]  \n",
    "    nodes = []\n",
    "    for node in all_nodes:\n",
    "        if len(nodes)>=n_subtrees:break\n",
    "        if node in nodes:\n",
    "            nodes.remove(node)\n",
    "        nodes.extend([node.get_left(), node.get_right()])\n",
    "    return nodes\n",
    "\n",
    "# Function that takes as input a node id and returns the ids of all leaf nodes under that node.\n",
    "def get_node_leaves(node):\n",
    "    if node.is_leaf():\n",
    "        return [node.id]\n",
    "    leaves = node.right.pre_order(lambda x: x.id)+node.left.pre_order(lambda x: x.id)\n",
    "    return leaves\n",
    "\n",
    "# Function to split a tree into n subtrees.\n",
    "# The function takes as input a scipy hierarchical tree object and a desired number of subtrees.\n",
    "# It outputs 2d list of node ids corresponding to the ids of the leaf nodes in each subtree.\n",
    "def get_tree_clusters(tree, n_subtrees):\n",
    "    nodes = get_cluster_nodes(tree, n_subtrees)\n",
    "    leaves = []\n",
    "    for node in nodes:\n",
    "        leaves.append(get_node_leaves(node))\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of subtrees\n",
    "n_subtrees = 6\n",
    "# Get tree object from hierarchical clustering of GNN matrix\n",
    "tree_nuts2 = get_tree(gnn_nuts2_dfg)\n",
    "# Divide tree into n subtrees (clusters) and get a list of the leaf nodes in each subtree\n",
    "tree_clusters_nuts2 = get_tree_clusters(tree_nuts2, n_subtrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Create a colourmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we colour-code each NUTS-2 area based on the subtree it is located in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses the tree object and the subtrees defined above and identifies the subtree each NUTS area is located in.\n",
    "def get_nuts_cluster(tree_clusters, gnn_dfg, poly_df):\n",
    "    poly_df['clusters'] = 0\n",
    "    for i in range(len(tree_clusters)):\n",
    "        for node_id in tree_clusters[i]:\n",
    "            node = gnn_dfg.index.values[node_id]\n",
    "#             index = poly_df.loc[poly_df['code']==node].index.values[0]\n",
    "            index = poly_df[poly_df['name']==node].index.values[0]\n",
    "            print(index)\n",
    "            poly_df.loc[index,'clusters'] = i\n",
    "    return poly_df\n",
    "\n",
    "# This function creates a colourmap based on the subtrees identified above and assign to each NUTS area a colour\n",
    "def get_colourmap(n_subtrees, poly_df):\n",
    "    cmap = plt.cm.get_cmap('Set2', n_subtrees+1)\n",
    "    colourmap = dict(zip(poly_df['code'], cmap(poly_df['clusters'])))\n",
    "    return colourmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df_nuts2 = get_nuts_cluster(tree_clusters_nuts2, gnn_nuts2_dfg, poly_df_nuts2)\n",
    "colourmap = get_colourmap(n_subtrees, poly_df_nuts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Plot a geographical map of the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,20))\n",
    "projection = ccrs.OSGB()\n",
    "ax = plt.axes(projection=projection)\n",
    "ax.coastlines(resolution='10m', linewidth=1.6)\n",
    "\n",
    "# Plot polygons\n",
    "\n",
    "#Default parameters\n",
    "facecolor = [0.9375, 0.9375, 0.859375]\n",
    "edgecolor = 'black'\n",
    "linewidth=10\n",
    "# Row-specific parameters\n",
    "for index in poly_df_nuts2.index:\n",
    "    name = poly_df_nuts2.at[index,'code']\n",
    "    geometry = poly_df_nuts2.at[index,'geometry']\n",
    "    facecolor = colourmap[name]\n",
    "    ax.add_geometries([geometry], ccrs.PlateCarree(), facecolor=facecolor, edgecolor=edgecolor)    \n",
    "    \n",
    "# Add the coastline of Ireland\n",
    "facecolor = 'white'\n",
    "edgecolor = 'black'\n",
    "name = names_RI\n",
    "ax.add_geometries(geometries_RI, ccrs.PlateCarree(), facecolor=facecolor, edgecolor=edgecolor)\n",
    "\n",
    "plt.savefig(\"UK_map.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Plot a heatmap representation of the GNN matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rotate poition of branchpoints in the hierarchical tree\n",
    "def rotate_linkage(linkage, index):\n",
    "    x, y = linkage[index][0:2]\n",
    "    linkage[index][0] = y\n",
    "    linkage[index][1] = x\n",
    "    \n",
    "# Function to rename NUTS areas by code instead of name\n",
    "def rename_gnn_sets(poly_df, gnn_dfg):\n",
    "    name_code_dict = dict(zip(poly_df['name'], poly_df['code']))\n",
    "    gnn_dfg.rename(columns=name_code_dict, inplace=True)\n",
    "    gnn_dfg.rename(index=name_code_dict, inplace=True)\n",
    "    return gnn_dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gnn_nuts2_dfg = rename_gnn_sets(poly_df_nuts2, gnn_nuts2_dfg)\n",
    "\n",
    "row_linkage = scipy.cluster.hierarchy.linkage(gnn_nuts2_dfg, method=\"average\")\n",
    "rotate_linkage(row_linkage, -1)\n",
    "order = scipy.cluster.hierarchy.leaves_list(row_linkage)\n",
    "x_pop = gnn_nuts2_dfg.index.values[order]\n",
    "row_colors = pd.Series(gnn_nuts2_dfg.reindex(x_pop).index, index=gnn_nuts2_dfg.reindex(x_pop).index).map(colourmap)\n",
    "\n",
    "cg = sns.clustermap(gnn_nuts2_dfg[x_pop], row_linkage=row_linkage, col_cluster=False, row_colors=row_colors, figsize=(20, 20))\n",
    "cg.ax_row_dendrogram.set_visible(False)  # Set to True to display the dendrogram\n",
    "plt.savefig(\"gnn_heatmap.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Output files:**\n",
    "* `UK_map.pdf` - Geographical map of the UK divided into NUTS-2 areas, where each area is colour-coded based on its position in the hierarchical tree.\n",
    "* `gnn_heatmap.pdf` - Heatmap plot of the NUTS-2 GNN matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Plot the geographical map of a specific row of the NUTS-3 GNN matrix\n",
    "See Figure 5 C,D,E on the tsinfer paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we use `gnn_nuts3_dfg`to plot a geographical representation of the GNN proportions of a specific NUTS-3 area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_df(df):\n",
    "    df_t = df.transpose()\n",
    "    df_t.index.name = df.index.name\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose GNN matrix to plot a column. This facilitates the manipulation of the dataframe.\n",
    "gnn_nuts3_dfg_t = transpose_df(gnn_nuts3_dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GNN_row(gnn_dfg_t, poly_df, nuts_area):\n",
    "    \n",
    "    # Extract column containing to the GNN proportions of the indicated NUTS area\n",
    "    area_gnn = poly_df.merge(gnn_dfg_t[nuts_area], left_on='name', right_on='place_of_birth')\n",
    "\n",
    "    # Define log-normalization scale based on min and max values in the gnn matrix\n",
    "    vmin = gnn_dfg_t.loc[gnn_dfg_t.stack().idxmin()]\n",
    "    vmax = gnn_dfg_t.loc[gnn_dfg_t.stack().idxmax()]\n",
    "    diff = 1-vmin     # translate values by 1\n",
    "    norm = colors.LogNorm(vmin=vmin+diff, vmax=vmax+diff)\n",
    "    \n",
    "    # Create colourmap \n",
    "    cmap = plt.get_cmap('pink_r') # more colormaps here: https://matplotlib.org/3.1.0/gallery/color/colormap_reference.html\n",
    "    colours = cmap(norm((area_gnn[nuts_area].fillna(0).values)+diff))\n",
    "    colourmap = dict(zip(area_gnn['name'], colours))\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10,20))\n",
    "    projection = ccrs.OSGB()\n",
    "    ax = plt.axes(projection=projection)\n",
    "    edgecolor = None\n",
    "    ax.coastlines(resolution='10m', linewidth=0.8)\n",
    "    # Plot polygons\n",
    "    # Default parameters\n",
    "    facecolor = [0.9375, 0.9375, 0.859375]\n",
    "    edgecolor = None\n",
    "    # Row-specific parameters\n",
    "    for index in area_gnn.index:\n",
    "        facecolor = colours[index]\n",
    "        geometry = area_gnn.at[index,'geometry']\n",
    "        ax.add_geometries([geometry], ccrs.PlateCarree(),facecolor=facecolor, edgecolor=edgecolor)\n",
    "    \n",
    "    # Add Ireland coastline\n",
    "    facecolor = 'white'\n",
    "    edgecolor = None\n",
    "    name = names_RI\n",
    "    ax.add_geometries(geometries_RI, ccrs.PlateCarree(), facecolor=facecolor, edgecolor=edgecolor)\n",
    "    \n",
    "    names = list(poly_df['name'])\n",
    "    geometries = list(poly_df['geometry'])\n",
    "    area_index = names.index(nuts_area)\n",
    "    point = geometries[area_index].centroid\n",
    "    x = point.coords[0][0]\n",
    "    y = point.coords[0][1]\n",
    "    ax.text(x, y, nuts_area, fontsize=14, fontweight='bold', transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add colourbar    \n",
    "    mapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    mapper.set_array(list(area_gnn[nuts_area]))\n",
    "    plt.colorbar(mapper, shrink=0.6, ticks=[1,2,4,6,8,10,12,14], format='%.0f')\n",
    "    \n",
    "    plt.savefig(\"gnn_row_map_\"+nuts_area+\".pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot row of the GNN matrix\n",
    "# Input NUTS-3 area name below. A list of all area names can be found in the dataframe poly_df_nuts3 or in the file \"UK_NUTS_Level_3_January_2018_Names_and_Countries.csv\".\n",
    "nuts_area = \"North Yorkshire CC\" \n",
    "plot_GNN_row(gnn_nuts3_dfg_t, poly_df_nuts3, nuts_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Output file:**\n",
    "* `gnn_row_map_nuts_area.pdf` - Geographical representation of the GNN proportions of a specific NUTS-3 area (generated by plotting a row of the NUTS-3 GNN matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "427px",
    "left": "1911px",
    "top": "179px",
    "width": "627px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
